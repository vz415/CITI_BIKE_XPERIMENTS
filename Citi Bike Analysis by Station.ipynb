{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citi Bike Analysis of Station Prediction\n",
    "So far I have built an ARIMA model with parameters optimized for the total system's output. I'll now implement those parameters for all of the stations in the system. I expect the results to vary dramatically, as the mean and variance amount of rides per day, by station, has been shown to differ greatly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincent_zaballa/anaconda3/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "# For time series analysis\n",
    "from statsmodels.tsa import stattools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincent_zaballa/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/vincent_zaballa/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/vincent_zaballa/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Wrangling in one Step\n",
    "# Specify columns to use\n",
    "columns = ['bikeid', 'birth year', 'end station id', \n",
    "           'end station latitude', 'end station longitude', 'end station name',\n",
    "           'gender', 'start station id', 'start station latitude', 'start station longitude',\n",
    "           'start station name', 'starttime', 'stoptime', 'tripduration', 'usertype']\n",
    "\n",
    "# use your path\n",
    "path = r'/Users/vincent_zaballa/Springboard_Assignments/capstone_proj_2/CITI_BIKE/2016_data' \n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "# Appending all imported dataframes to empty df\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in all_files:\n",
    "    df = pd.read_csv(file_, index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "bike_df = pd.concat(list_)\n",
    "\n",
    "# Naming columns for future use\n",
    "bike_df.columns = columns + bike_df.columns[15:].tolist()\n",
    "\n",
    "# Creating left and right dfs\n",
    "right_df = bike_df[bike_df.iloc[:,0].notnull() == False]\n",
    "left_df = bike_df[bike_df.iloc[:,0].notnull() == True]\n",
    "right_df = right_df.dropna(axis=1, how='all')\n",
    "left_df = left_df.dropna(axis=1, how='all')\n",
    "\n",
    "# Convert individual dfs' timestamps\n",
    "# Need to convert two different format dfs to timestamp beforehand to speed things up MASSIVELY\n",
    "right_df.starttime = pd.to_datetime(right_df.starttime, format='%m/%d/%Y %H:%M:%S')\n",
    "right_df.stoptime = pd.to_datetime(right_df.stoptime, format='%m/%d/%Y %H:%M:%S')\n",
    "left_df.starttime = pd.to_datetime(left_df.starttime, format='%Y-%m-%d %H:%M:%S')\n",
    "left_df.stoptime = pd.to_datetime(left_df.stoptime, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Combining\n",
    "frames = [right_df, left_df]\n",
    "bike_df = pd.concat(frames, axis=0)\n",
    "\n",
    "# Setting starttime as the index\n",
    "bike_df.index = bike_df['starttime']\n",
    "bike_df = bike_df.sort_index()\n",
    "\n",
    "# Fixing Null Values\n",
    "# Setting NaN values equal to average age\n",
    "bike_df[bike_df['birth year'].notnull() == False] = np.ceil(bike_df['birth year'].mean()).astype(int)\n",
    "\n",
    "# Converting the whole column to int to save space\n",
    "bike_df.loc[:,'birth year'] = bike_df['birth year'].copy().astype(int)\n",
    "bike_df.loc[:,'tripduration'] = bike_df['tripduration'].copy().astype(int)\n",
    "bike_df.loc[:,'end station id'] = bike_df['end station id'].copy().astype(int)\n",
    "bike_df.loc[:,'start station id'] = bike_df['start station id'].copy().astype(int)\n",
    "bike_df.loc[:,'gender'] = bike_df['gender'].copy().astype(int)\n",
    "bike_df.loc[:,'bikeid'] = bike_df['bikeid'].copy().astype(int)\n",
    "\n",
    "# Create a one-time user gender class (unknown) instead of \"Other\" class\n",
    "bike_df.loc[:,'gender'].loc[bike_df['usertype'] == 'Customer'] = 3\n",
    "\n",
    "# Fixing a station's lat/lon\n",
    "bike_df.loc[:, 'end station latitude'][bike_df['end station name'] == 'NYCBS Depot BAL - DYR'] = 40.75903008\n",
    "bike_df.loc[:, 'end station longitude'][bike_df['end station name'] == 'NYCBS Depot BAL - DYR'] = -73.9938587\n",
    "\n",
    "# Deleting anomalous (no data) station\n",
    "bike_df = bike_df[bike_df['end station name'] != 'SSP - Basement']\n",
    "\n",
    "# Removing the missing start station lat/lons\n",
    "bike_df = bike_df[bike_df['start station longitude'] != 0]\n",
    "\n",
    "# Creating distance travelled\n",
    "# Distance travelled - vectorized\n",
    "bike_df['LAT_start_rad'], bike_df['LON_start_rad'] = np.radians(bike_df['start station latitude']), np.radians(bike_df['start station longitude'])\n",
    "bike_df['LAT_end_rad'], bike_df['LON_end_rad'] = np.radians(bike_df['end station latitude']), np.radians(bike_df['end station longitude'])\n",
    "bike_df['dLON'] = bike_df['LON_end_rad'] - bike_df['LON_start_rad']\n",
    "bike_df['dLAT'] = bike_df['LAT_end_rad'] - bike_df['LAT_start_rad']\n",
    "bike_df['distance_miles'] = 3961 * 2 * np.arcsin(np.sqrt(\n",
    "    np.sin(bike_df['dLAT']/2)**2 + np.cos(bike_df['LAT_start_rad']) * np.cos(bike_df['LAT_end_rad']) * np.sin(bike_df['dLON']/2)**2\n",
    "))\n",
    "del bike_df['LON_start_rad'], bike_df['LAT_start_rad'], bike_df['LAT_end_rad'], bike_df['LON_end_rad'], bike_df['dLON'], bike_df['dLAT']\n",
    "\n",
    "\n",
    "# Average velocity - Assuming they went in a straight line and were moving the entire time...\n",
    "bike_df['speed_miles/hour'] = bike_df['distance_miles'] / (bike_df['tripduration']/3600)\n",
    "\n",
    "# deleting max speed data error (trip duration way too long)\n",
    "bike_df = bike_df.loc[bike_df['speed_miles/hour'] != bike_df['speed_miles/hour'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Optimal ARIMA Parameters\n",
    "We know that the optimal ARIMA parameters for the system were (4,2,2). I can apply that to all of the Citi Bike Stations. I'll collect and aggregate the number of bikes leaving a station by day, apply the ARIMA model parameters to the stations, and evaluate the RMSE for all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start station id</th>\n",
       "      <th>rides_leaving</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>79</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>83</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>116</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start station id  rides_leaving\n",
       "date                                       \n",
       "2016-01-01                72             19\n",
       "2016-01-01                79             15\n",
       "2016-01-01                82             10\n",
       "2016-01-01                83             14\n",
       "2016-01-01               116             39"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the mean number of bikes leaving per day by station\n",
    "bike_df['date'] = bike_df.index.date\n",
    "start_station_df = bike_df.groupby(['date', 'start station id']).size()\n",
    "start_station_df = start_station_df.reset_index('start station id')\n",
    "start_station_df = start_station_df.rename(columns={0: \"rides_leaving\"})\n",
    "start_station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(start_station_df['start station id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 650 unique stations in the dataset. So, I'll need to go through each unique station, for each day, and compute the RMSE for each station's output with the (4,2,2) ARIMA model and its actual output. First, I need to make a pivot table of the stations, rides, and dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>start station id</th>\n",
       "      <th>72</th>\n",
       "      <th>79</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>116</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>137</th>\n",
       "      <th>...</th>\n",
       "      <th>3235</th>\n",
       "      <th>3236</th>\n",
       "      <th>3237</th>\n",
       "      <th>3238</th>\n",
       "      <th>3241</th>\n",
       "      <th>3242</th>\n",
       "      <th>3243</th>\n",
       "      <th>3244</th>\n",
       "      <th>3246</th>\n",
       "      <th>3249</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>51</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "      <td>86</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "start station id  72    79    82    83    116   119   120   127   128   137   \\\n",
       "date                                                                           \n",
       "2016-01-01          19    15    10    14    39     2     4    20    43     4   \n",
       "2016-01-02          26    19    17    15    56     0    13    41    42    19   \n",
       "2016-01-03          17    29    14    24    58     2    12    60    54    12   \n",
       "2016-01-04          51    36    16    10    92     3     8   118    86    51   \n",
       "2016-01-05          46    27    17    17    93     4     6    79    70    46   \n",
       "\n",
       "start station id  ...   3235  3236  3237  3238  3241  3242  3243  3244  3246  \\\n",
       "date              ...                                                          \n",
       "2016-01-01        ...      5     0     2    19     1     3     0     0     0   \n",
       "2016-01-02        ...      7     0     2    14     2     6     0     0     0   \n",
       "2016-01-03        ...     12     0     3     7     6    15     4     0     0   \n",
       "2016-01-04        ...     67   123     0     5     3     8     9     0     0   \n",
       "2016-01-05        ...     47    38     1    16     2     5     8     0     0   \n",
       "\n",
       "start station id  3249  \n",
       "date                    \n",
       "2016-01-01           0  \n",
       "2016-01-02           0  \n",
       "2016-01-03           0  \n",
       "2016-01-04           0  \n",
       "2016-01-05           0  \n",
       "\n",
       "[5 rows x 457 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_station_pivot = start_station_df.pivot_table(values='rides_leaving', index='date', columns='start station id')\n",
    "start_station_pivot = start_station_pivot.dropna(axis=1, thresh=250) #threshold of at least 250 non-nan values\n",
    "start_station_pivot = start_station_pivot.fillna(value=0).astype(int)\n",
    "start_station_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_station_pivot.index = pd.to_datetime(start_station_pivot.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the demand station pivot table, we saw that there are many stations that do not have any values for the first part of the year. From the data story, we know that some stations opened beginning of September or late August of the year. Since those stations won't have enough samples to train a model on, I removed them before applying ARIMA models to all of the stations. The criteria for removal was that the station needed to have at least **250** values in order for me to use the station for ARIMA modeling.\n",
    "\n",
    "## Applying ARIMA Models to Individual Stations\n",
    "I will now apply the (4,2,2) ARIMA model to all of the stations. I will measure the RMSE for the prediction and provide an analysis of the distribution of RMSE, which stations performed best, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  72,   79,   82,   83,  116,  119,  120,  127,  128,  137,\n",
       "            ...\n",
       "            3235, 3236, 3237, 3238, 3241, 3242, 3243, 3244, 3246, 3249],\n",
       "           dtype='int64', name='start station id', length=457)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_station_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying ARIMA to all stations\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "    # prepare training dataset\n",
    "    train_size = int(len(X) * 0.7)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate out of sample error\n",
    "    rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def ARIMA_fitter(df, arima_order):\n",
    "    '''\n",
    "    Function takes a dataframe with an index that has a datetime index with a normalized frequency,\n",
    "    columns that represent equivalent features, and the (p,d,q) order for the ARIMA model.\n",
    "    \n",
    "    The function will return a list of RMSE values that correspond to the order of the columns provided\n",
    "    by the df input. Future edits may make this a dictionary instead of a list.\n",
    "    '''\n",
    "    RMSE_list = []\n",
    "    col_list = []\n",
    "    for col in df.columns:\n",
    "        X = df.loc[:,col].values.astype(float)\n",
    "        best_score = float(\"inf\")\n",
    "        print('Evaluating station:', col)\n",
    "        \n",
    "        try:\n",
    "            rmse = evaluate_arima_model(X, arima_order)\n",
    "            if rmse < best_score:\n",
    "                best_score = rmse\n",
    "                col_list.append(col)\n",
    "                RMSE_list.append(best_score)\n",
    "            print('ARIMA RMSE=%.3f'  % (rmse))\n",
    "        except:\n",
    "            print('ARIMA Model could not converge')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    return dict(zip(col_list, RMSE_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating station: 72\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 79\n",
      "ARIMA RMSE=22.128\n",
      "Evaluating station: 82\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 83\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 116\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 119\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 120\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 127\n",
      "ARIMA RMSE=53.597\n",
      "Evaluating station: 128\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 137\n",
      "ARIMA RMSE=24.419\n",
      "Evaluating station: 143\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 144\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 146\n",
      "ARIMA RMSE=20.738\n",
      "Evaluating station: 147\n",
      "ARIMA RMSE=36.287\n",
      "Evaluating station: 150\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 151\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 152\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 153\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 157\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 161\n",
      "ARIMA RMSE=43.759\n",
      "Evaluating station: 164\n",
      "ARIMA RMSE=35.017\n",
      "Evaluating station: 167\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 168\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 173\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 174\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 195\n",
      "ARIMA RMSE=39.179\n",
      "Evaluating station: 212\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 216\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 217\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 224\n",
      "ARIMA RMSE=17.786\n",
      "Evaluating station: 225\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 228\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 229\n",
      "ARIMA RMSE=53.503\n",
      "Evaluating station: 232\n",
      "ARIMA RMSE=10.600\n",
      "Evaluating station: 236\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 237\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 238\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 239\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 241\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 242\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 243\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 244\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 245\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 247\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 248\n",
      "ARIMA RMSE=15.628\n",
      "Evaluating station: 249\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 251\n",
      "ARIMA RMSE=34.793\n",
      "Evaluating station: 252\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 253\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 254\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 257\n",
      "ARIMA RMSE=26.375\n",
      "Evaluating station: 258\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 259\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 260\n",
      "ARIMA RMSE=21.925\n",
      "Evaluating station: 261\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 262\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 263\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 264\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 265\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 266\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 267\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 268\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 270\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 274\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 275\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 276\n",
      "ARIMA RMSE=18.376\n",
      "Evaluating station: 278\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 279\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 280\n",
      "ARIMA RMSE=22.410\n",
      "Evaluating station: 281\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 282\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 284\n",
      "ARIMA RMSE=56.546\n",
      "Evaluating station: 285\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 289\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 291\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 295\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 296\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 297\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 298\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 301\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 302\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 303\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 304\n",
      "ARIMA RMSE=52.728\n",
      "Evaluating station: 305\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 306\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 307\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 308\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 309\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 310\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 311\n",
      "ARIMA RMSE=18.822\n",
      "Evaluating station: 312\n",
      "ARIMA RMSE=31.825\n",
      "Evaluating station: 313\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 315\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 316\n",
      "ARIMA RMSE=22.031\n",
      "Evaluating station: 317\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 319\n",
      "ARIMA RMSE=24.414\n",
      "Evaluating station: 320\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 321\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 322\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 323\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 324\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 325\n",
      "ARIMA RMSE=25.367\n",
      "Evaluating station: 326\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 327\n",
      "ARIMA RMSE=56.960\n",
      "Evaluating station: 328\n",
      "ARIMA RMSE=23.366\n",
      "Evaluating station: 329\n",
      "ARIMA RMSE=25.102\n",
      "Evaluating station: 330\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 331\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 332\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 334\n",
      "ARIMA RMSE=40.319\n",
      "Evaluating station: 335\n",
      "ARIMA RMSE=43.632\n",
      "Evaluating station: 336\n",
      "ARIMA RMSE=30.094\n",
      "Evaluating station: 337\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 339\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 340\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 341\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 342\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 343\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 344\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 345\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 346\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 347\n",
      "ARIMA RMSE=50.912\n",
      "Evaluating station: 348\n",
      "ARIMA RMSE=33.818\n",
      "Evaluating station: 349\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 350\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 351\n",
      "ARIMA RMSE=22.160\n",
      "Evaluating station: 352\n",
      "ARIMA RMSE=37.629\n",
      "Evaluating station: 353\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 354\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 355\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 356\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 357\n",
      "ARIMA RMSE=32.628\n",
      "Evaluating station: 358\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 359\n",
      "ARIMA RMSE=123.789\n",
      "Evaluating station: 360\n",
      "ARIMA RMSE=22.623\n",
      "Evaluating station: 361\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 362\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 363\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 364\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 365\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 366\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 367\n",
      "ARIMA RMSE=60.412\n",
      "Evaluating station: 368\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 369\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 372\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 373\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 376\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 377\n",
      "ARIMA RMSE=31.521\n",
      "Evaluating station: 379\n",
      "ARIMA RMSE=67.581\n",
      "Evaluating station: 380\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 382\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 383\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 384\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 385\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 386\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 387\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 388\n",
      "ARIMA RMSE=55.212\n",
      "Evaluating station: 389\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 390\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA Model could not converge\n",
      "Evaluating station: 392\n",
      "ARIMA RMSE=20.176\n",
      "Evaluating station: 393\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 394\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 395\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 396\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 397\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 398\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 399\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 400\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 401\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 402\n",
      "ARIMA RMSE=99.799\n",
      "Evaluating station: 405\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 406\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 407\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 408\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 409\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 410\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 411\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 412\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 414\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 415\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 416\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 417\n",
      "ARIMA RMSE=49.419\n",
      "Evaluating station: 418\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 419\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 420\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 421\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 422\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 423\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 426\n",
      "ARIMA RMSE=70.152\n",
      "Evaluating station: 427\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 428\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 430\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 432\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 433\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 434\n",
      "ARIMA RMSE=50.153\n",
      "Evaluating station: 435\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 436\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 437\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 438\n",
      "ARIMA RMSE=28.852\n",
      "Evaluating station: 439\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 440\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 441\n",
      "ARIMA RMSE=27.464\n",
      "Evaluating station: 442\n",
      "ARIMA RMSE=63.361\n",
      "Evaluating station: 443\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 444\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 445\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 446\n",
      "ARIMA RMSE=53.799\n",
      "Evaluating station: 447\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 448\n",
      "ARIMA RMSE=37.249\n",
      "Evaluating station: 449\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 450\n",
      "ARIMA RMSE=49.693\n",
      "Evaluating station: 453\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 454\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 455\n",
      "ARIMA RMSE=39.013\n",
      "Evaluating station: 456\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 457\n",
      "ARIMA RMSE=43.895\n",
      "Evaluating station: 458\n",
      "ARIMA RMSE=43.616\n",
      "Evaluating station: 459\n",
      "ARIMA RMSE=61.300\n",
      "Evaluating station: 460\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 461\n",
      "ARIMA RMSE=47.463\n",
      "Evaluating station: 462\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 465\n",
      "ARIMA RMSE=27.176\n",
      "Evaluating station: 466\n",
      "ARIMA RMSE=49.961\n",
      "Evaluating station: 467\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 468\n",
      "ARIMA RMSE=57.731\n",
      "Evaluating station: 469\n",
      "ARIMA RMSE=41.237\n",
      "Evaluating station: 470\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 471\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 472\n",
      "ARIMA RMSE=64.693\n",
      "Evaluating station: 473\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 474\n",
      "ARIMA RMSE=47.860\n",
      "Evaluating station: 475\n",
      "ARIMA RMSE=42.591\n",
      "Evaluating station: 476\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 477\n",
      "ARIMA RMSE=87.663\n",
      "Evaluating station: 478\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 479\n",
      "ARIMA RMSE=38.682\n",
      "Evaluating station: 480\n",
      "ARIMA RMSE=24.400\n",
      "Evaluating station: 481\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 482\n",
      "ARIMA RMSE=39.644\n",
      "Evaluating station: 483\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 484\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 485\n",
      "ARIMA RMSE=38.923\n",
      "Evaluating station: 486\n",
      "ARIMA RMSE=56.821\n",
      "Evaluating station: 487\n",
      "ARIMA RMSE=35.889\n",
      "Evaluating station: 488\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 490\n",
      "ARIMA RMSE=75.577\n",
      "Evaluating station: 491\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 492\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 493\n",
      "ARIMA RMSE=38.811\n",
      "Evaluating station: 494\n",
      "ARIMA RMSE=42.315\n",
      "Evaluating station: 495\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 496\n",
      "ARIMA RMSE=51.904\n",
      "Evaluating station: 497\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 498\n",
      "ARIMA RMSE=61.484\n",
      "Evaluating station: 499\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 500\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 501\n",
      "ARIMA RMSE=25.086\n",
      "Evaluating station: 502\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 503\n",
      "ARIMA RMSE=45.837\n",
      "Evaluating station: 504\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 505\n",
      "ARIMA RMSE=57.288\n",
      "Evaluating station: 507\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 508\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 509\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 511\n",
      "ARIMA RMSE=56.628\n",
      "Evaluating station: 513\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 514\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 515\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 516\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 517\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 518\n",
      "ARIMA RMSE=57.832\n",
      "Evaluating station: 519\n",
      "ARIMA RMSE=191.234\n",
      "Evaluating station: 520\n",
      "ARIMA RMSE=104.964\n",
      "Evaluating station: 522\n",
      "ARIMA RMSE=36.707\n",
      "Evaluating station: 523\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 524\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 525\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 526\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 527\n",
      "ARIMA RMSE=47.399\n",
      "Evaluating station: 528\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 529\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 530\n",
      "ARIMA RMSE=33.557\n",
      "Evaluating station: 531\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 532\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 533\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 534\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 536\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 537\n",
      "ARIMA RMSE=54.298\n",
      "Evaluating station: 539\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 540\n",
      "ARIMA RMSE=49.357\n",
      "Evaluating station: 545\n",
      "ARIMA RMSE=21.914\n",
      "Evaluating station: 546\n",
      "ARIMA RMSE=45.553\n",
      "Evaluating station: 1978\n",
      "ARIMA RMSE=1935.773\n",
      "Evaluating station: 2000\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2001\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2002\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2003\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2004\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2005\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2006\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2008\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2009\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2010\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2012\n",
      "ARIMA RMSE=36.770\n",
      "Evaluating station: 2017\n",
      "ARIMA RMSE=28.830\n",
      "Evaluating station: 2021\n",
      "ARIMA RMSE=40.337\n",
      "Evaluating station: 2022\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 2023\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3002\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3016\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3041\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3042\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3043\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3044\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3046\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3047\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3048\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3049\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3050\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3052\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3053\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA Model could not converge\n",
      "Evaluating station: 3055\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3056\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3057\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3058\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3059\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3060\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3061\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3062\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3063\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3064\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3065\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3066\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3067\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3068\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3069\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3070\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3071\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3072\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3073\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3074\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3075\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3076\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3077\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3078\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3079\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3080\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3081\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3082\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3083\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3084\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3085\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3086\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3087\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3088\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3089\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3090\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3091\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3092\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3093\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3094\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3095\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3096\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3098\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3099\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3100\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3101\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3102\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3103\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3105\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3106\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3107\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3108\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3109\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3110\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3111\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3112\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3113\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3114\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3115\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3116\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3117\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3118\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3119\n",
      "ARIMA RMSE=21.082\n",
      "Evaluating station: 3120\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3121\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3122\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3123\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3124\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3125\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3126\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3127\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3128\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3129\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3131\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3132\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3134\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3135\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3137\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3139\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3140\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3141\n",
      "ARIMA RMSE=66.777\n",
      "Evaluating station: 3142\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3143\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3144\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3145\n",
      "ARIMA RMSE=18.453\n",
      "Evaluating station: 3146\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3147\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3148\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3150\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3151\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3153\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3155\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3156\n",
      "ARIMA RMSE=40.225\n",
      "Evaluating station: 3157\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3158\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3159\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3160\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3161\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3162\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3163\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3164\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3165\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3166\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3167\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3168\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3169\n",
      "ARIMA RMSE=16.174\n",
      "Evaluating station: 3170\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3171\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3172\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3173\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3175\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3176\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3177\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3178\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3179\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3180\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3221\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3223\n",
      "ARIMA RMSE=34.478\n",
      "Evaluating station: 3224\n",
      "ARIMA RMSE=41.435\n",
      "Evaluating station: 3226\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3230\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3231\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3232\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3233\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3235\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3236\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3237\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3238\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3241\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3242\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3243\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3244\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3246\n",
      "ARIMA Model could not converge\n",
      "Evaluating station: 3249\n",
      "ARIMA Model could not converge\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.127930989952468,\n",
       " 53.596818283625545,\n",
       " 24.419090198279278,\n",
       " 20.738325125001424,\n",
       " 36.287266921335736,\n",
       " 43.758683711391377,\n",
       " 35.017351109998962,\n",
       " 39.178936015749684,\n",
       " 17.786338157406639,\n",
       " 53.503308235558521,\n",
       " 10.600129222594761,\n",
       " 15.628203670729812,\n",
       " 34.793314987871291,\n",
       " 26.374724179200275,\n",
       " 21.924699877075813,\n",
       " 18.376430086018818,\n",
       " 22.409825336527835,\n",
       " 56.546061472733726,\n",
       " 52.7281790141651,\n",
       " 18.822010561912279,\n",
       " 31.825359000263855,\n",
       " 22.031410681798697,\n",
       " 24.414022208888881,\n",
       " 25.366998954993747,\n",
       " 56.95978342838508,\n",
       " 23.365763598321774,\n",
       " 25.101930255757186,\n",
       " 40.31928586300247,\n",
       " 43.631691735608307,\n",
       " 30.094101376168442,\n",
       " 50.912441848213717,\n",
       " 33.818473241149199,\n",
       " 22.160047403131657,\n",
       " 37.629137573122243,\n",
       " 32.628246605252215,\n",
       " 123.78926850614623,\n",
       " 22.623246144021842,\n",
       " 60.41221251140221,\n",
       " 31.520504815460409,\n",
       " 67.580837118176987,\n",
       " 55.21203372414746,\n",
       " 20.176406400558765,\n",
       " 99.799095265005604,\n",
       " 49.419189446281926,\n",
       " 70.151832624475162,\n",
       " 50.153166392489361,\n",
       " 28.852148646154799,\n",
       " 27.463787827087518,\n",
       " 63.361065570041234,\n",
       " 53.799464199119114,\n",
       " 37.249030249046115,\n",
       " 49.69330582973997,\n",
       " 39.012715151561729,\n",
       " 43.895154128680936,\n",
       " 43.616070581954169,\n",
       " 61.299667101368648,\n",
       " 47.463312805438413,\n",
       " 27.175588467926762,\n",
       " 49.9612246541895,\n",
       " 57.730536316016988,\n",
       " 41.23682615715483,\n",
       " 64.69322243341486,\n",
       " 47.859857708984997,\n",
       " 42.591387416170058,\n",
       " 87.663416710079701,\n",
       " 38.681958960392592,\n",
       " 24.400257984180207,\n",
       " 39.644055123365355,\n",
       " 38.922938161411096,\n",
       " 56.820733992965252,\n",
       " 35.889001484801476,\n",
       " 75.577049862086227,\n",
       " 38.810586741689619,\n",
       " 42.314979719030141,\n",
       " 51.904018960637238,\n",
       " 61.484298064400235,\n",
       " 25.085588664454797,\n",
       " 45.837495116297021,\n",
       " 57.287962134780301,\n",
       " 56.628033501282843,\n",
       " 57.831751893900233,\n",
       " 191.23369570407178,\n",
       " 104.96423582080294,\n",
       " 36.707294450361246,\n",
       " 47.398969244070329,\n",
       " 33.55655920092893,\n",
       " 54.297506325523869,\n",
       " 49.357479677381157,\n",
       " 21.913926748921725,\n",
       " 45.55284142056329,\n",
       " 1935.7729166590968,\n",
       " 36.770096061239492,\n",
       " 28.830434989351318,\n",
       " 40.337176445874,\n",
       " 21.081996564217224,\n",
       " 66.777270385188132,\n",
       " 18.4533828784372,\n",
       " 40.225038110296595,\n",
       " 16.173725836294022,\n",
       " 34.478414344176713,\n",
       " 41.435465712487826]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# ignore warnings, as things are about to get messy\n",
    "ARIMA_fitter(start_station_pivot, (4,2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have a distribution of RSME for stations that could converge with ARIMA model parameters (4,2,2). Let's find the average RMSE, the station with the largest error, while still converging, and the station with the smallest error. Additionally, I will look at a station that did not converge to help understand why some stations did not converge. Next time I use this function, I will update it to return a dictionary with the station id and the RMSE for that station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations_RMSE = [22.127930989952468,\n",
    " 53.596818283625545,\n",
    " 24.419090198279278,\n",
    " 20.738325125001424,\n",
    " 36.287266921335736,\n",
    " 43.758683711391377,\n",
    " 35.017351109998962,\n",
    " 39.178936015749684,\n",
    " 17.786338157406639,\n",
    " 53.503308235558521,\n",
    " 10.600129222594761,\n",
    " 15.628203670729812,\n",
    " 34.793314987871291,\n",
    " 26.374724179200275,\n",
    " 21.924699877075813,\n",
    " 18.376430086018818,\n",
    " 22.409825336527835,\n",
    " 56.546061472733726,\n",
    " 52.7281790141651,\n",
    " 18.822010561912279,\n",
    " 31.825359000263855,\n",
    " 22.031410681798697,\n",
    " 24.414022208888881,\n",
    " 25.366998954993747,\n",
    " 56.95978342838508,\n",
    " 23.365763598321774,\n",
    " 25.101930255757186,\n",
    " 40.31928586300247,\n",
    " 43.631691735608307,\n",
    " 30.094101376168442,\n",
    " 50.912441848213717,\n",
    " 33.818473241149199,\n",
    " 22.160047403131657,\n",
    " 37.629137573122243,\n",
    " 32.628246605252215,\n",
    " 123.78926850614623,\n",
    " 22.623246144021842,\n",
    " 60.41221251140221,\n",
    " 31.520504815460409,\n",
    " 67.580837118176987,\n",
    " 55.21203372414746,\n",
    " 20.176406400558765,\n",
    " 99.799095265005604,\n",
    " 49.419189446281926,\n",
    " 70.151832624475162,\n",
    " 50.153166392489361,\n",
    " 28.852148646154799,\n",
    " 27.463787827087518,\n",
    " 63.361065570041234,\n",
    " 53.799464199119114,\n",
    " 37.249030249046115,\n",
    " 49.69330582973997,\n",
    " 39.012715151561729,\n",
    " 43.895154128680936,\n",
    " 43.616070581954169,\n",
    " 61.299667101368648,\n",
    " 47.463312805438413,\n",
    " 27.175588467926762,\n",
    " 49.9612246541895,\n",
    " 57.730536316016988,\n",
    " 41.23682615715483,\n",
    " 64.69322243341486,\n",
    " 47.859857708984997,\n",
    " 42.591387416170058,\n",
    " 87.663416710079701,\n",
    " 38.681958960392592,\n",
    " 24.400257984180207,\n",
    " 39.644055123365355,\n",
    " 38.922938161411096,\n",
    " 56.820733992965252,\n",
    " 35.889001484801476,\n",
    " 75.577049862086227,\n",
    " 38.810586741689619,\n",
    " 42.314979719030141,\n",
    " 51.904018960637238,\n",
    " 61.484298064400235,\n",
    " 25.085588664454797,\n",
    " 45.837495116297021,\n",
    " 57.287962134780301,\n",
    " 56.628033501282843,\n",
    " 57.831751893900233,\n",
    " 191.23369570407178,\n",
    " 104.96423582080294,\n",
    " 36.707294450361246,\n",
    " 47.398969244070329,\n",
    " 33.55655920092893,\n",
    " 54.297506325523869,\n",
    " 49.357479677381157,\n",
    " 21.913926748921725,\n",
    " 45.55284142056329,\n",
    " 1935.7729166590968,\n",
    " 36.770096061239492,\n",
    " 28.830434989351318,\n",
    " 40.337176445874,\n",
    " 21.081996564217224,\n",
    " 66.777270385188132,\n",
    " 18.4533828784372,\n",
    " 40.225038110296595,\n",
    " 16.173725836294022,\n",
    " 34.478414344176713,\n",
    " 41.435465712487826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935.7729166590968"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(stations_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.600129222594761"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(stations_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.403673591865761"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(stations_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.225038110296595"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(stations_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 29.,  37.,  27.,   2.,   3.,   1.,   0.,   0.,   0.,   1.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          1.]),\n",
       " array([   10.60012922,    29.8518571 ,    49.10358497,    68.35531285,\n",
       "           87.60704072,   106.85876859,   126.11049647,   145.36222434,\n",
       "          164.61395222,   183.86568009,   203.11740797,   222.36913584,\n",
       "          241.62086371,   260.87259159,   280.12431946,   299.37604734,\n",
       "          318.62777521,   337.87950309,   357.13123096,   376.38295884,\n",
       "          395.63468671,   414.88641458,   434.13814246,   453.38987033,\n",
       "          472.64159821,   491.89332608,   511.14505396,   530.39678183,\n",
       "          549.6485097 ,   568.90023758,   588.15196545,   607.40369333,\n",
       "          626.6554212 ,   645.90714908,   665.15887695,   684.41060483,\n",
       "          703.6623327 ,   722.91406057,   742.16578845,   761.41751632,\n",
       "          780.6692442 ,   799.92097207,   819.17269995,   838.42442782,\n",
       "          857.67615569,   876.92788357,   896.17961144,   915.43133932,\n",
       "          934.68306719,   953.93479507,   973.18652294,   992.43825082,\n",
       "         1011.68997869,  1030.94170656,  1050.19343444,  1069.44516231,\n",
       "         1088.69689019,  1107.94861806,  1127.20034594,  1146.45207381,\n",
       "         1165.70380168,  1184.95552956,  1204.20725743,  1223.45898531,\n",
       "         1242.71071318,  1261.96244106,  1281.21416893,  1300.46589681,\n",
       "         1319.71762468,  1338.96935255,  1358.22108043,  1377.4728083 ,\n",
       "         1396.72453618,  1415.97626405,  1435.22799193,  1454.4797198 ,\n",
       "         1473.73144767,  1492.98317555,  1512.23490342,  1531.4866313 ,\n",
       "         1550.73835917,  1569.99008705,  1589.24181492,  1608.49354279,\n",
       "         1627.74527067,  1646.99699854,  1666.24872642,  1685.50045429,\n",
       "         1704.75218217,  1724.00391004,  1743.25563792,  1762.50736579,\n",
       "         1781.75909366,  1801.01082154,  1820.26254941,  1839.51427729,\n",
       "         1858.76600516,  1878.01773304,  1897.26946091,  1916.52118878,\n",
       "         1935.77291666]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFJCAYAAACo8EWwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSMi9w23zigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103a90198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(stations_RMSE, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id_list = [79, 127, 137, 146, 147, 161, 164, 195, 224, 229, 232, 248, 251, 257, 260, 276, 280, 284, 304, 311, 312, 316, 319, 325, 327, 328, 329, 334, 335, 336, 347, 348, 351, 352, 357, 359, 360, 367, 377, 379, 388, 392, 402, 417, 426, 434, 438, 441, 442, 446, 448, 450, 455, 457, 458, 459, 461, 465, 466, 468, 469, 472, 474, 475, 477, 479, 480, 482, 485, 486, 487, 490, 493, 494, 496, 498, 501, 503, 505, 511, 518, 519, 520, 522, 527, 530, 537, 540, 545, 546, 1978, 2012, 2017, 2021, 3119, 3141, 3145, 3156, 3169, 3223, 3224]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id_RMSE = dict(zip(station_id_list, stations_RMSE))\n",
    "# Isolate the columns that converged from the original dataframe\n",
    "converged_df = start_station_pivot[station_id_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Persistence Model for all the stations that converged\n",
    "# Create lagged dataset\n",
    "def station_persistence(df):\n",
    "    '''\n",
    "    Takes a df series, shifts, creates a new df, and outputs the results of a persistence model on that df.\n",
    "    df should have no nan values. This function iterates over all columns, assuming they are of the same\n",
    "    type and have the same datetime indices. If there are different datetime indices, resampling should be\n",
    "    done to put them in the same order.\n",
    "    \n",
    "    Returns a dictionary with the column name and associated persistence model RMSE.\n",
    "    '''\n",
    "    RMSE_list = []\n",
    "    col_list = []\n",
    "    for col in df.columns:\n",
    "        persistence_dataframe = pd.concat([pd.DataFrame(converged_df[col]).shift(), pd.DataFrame(converged_df[col])], axis=1)\n",
    "        persistence_dataframe.columns = [ 't' ,  't+1' ]\n",
    "\n",
    "        # split into train and test sets\n",
    "        X = persistence_dataframe.values\n",
    "        train_size = int(len(X) * 0.7)\n",
    "        train, test = X[1:train_size], X[train_size:]\n",
    "        train_X, train_y = train[:,0], train[:,1]\n",
    "        test_X, test_y = test[:,0], test[:,1]\n",
    "\n",
    "        # persistence model\n",
    "        def model_persistence(x):\n",
    "            return x\n",
    "        \n",
    "        # walk-forward validation\n",
    "        predictions = list()\n",
    "        for x in test_X:\n",
    "            yhat = model_persistence(x)\n",
    "            predictions.append(yhat)\n",
    "        rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "        print('RMSE of persistence model for station %s: %.3f' % (col, rmse))\n",
    "        RMSE_list.append(rmse)\n",
    "        col_list.append(col)\n",
    "    return dict(list(zip(col_list, RMSE_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of persistence model for station 79: 25.924\n",
      "RMSE of persistence model for station 127: 65.402\n",
      "RMSE of persistence model for station 137: 27.337\n",
      "RMSE of persistence model for station 146: 24.817\n",
      "RMSE of persistence model for station 147: 43.409\n",
      "RMSE of persistence model for station 161: 51.458\n",
      "RMSE of persistence model for station 164: 43.885\n",
      "RMSE of persistence model for station 195: 49.481\n",
      "RMSE of persistence model for station 224: 20.757\n",
      "RMSE of persistence model for station 229: 65.918\n",
      "RMSE of persistence model for station 232: 12.172\n",
      "RMSE of persistence model for station 248: 18.767\n",
      "RMSE of persistence model for station 251: 38.954\n",
      "RMSE of persistence model for station 257: 31.655\n",
      "RMSE of persistence model for station 260: 24.222\n",
      "RMSE of persistence model for station 276: 20.625\n",
      "RMSE of persistence model for station 280: 27.951\n",
      "RMSE of persistence model for station 284: 64.613\n",
      "RMSE of persistence model for station 304: 68.370\n",
      "RMSE of persistence model for station 311: 21.645\n",
      "RMSE of persistence model for station 312: 36.203\n",
      "RMSE of persistence model for station 316: 26.514\n",
      "RMSE of persistence model for station 319: 29.159\n",
      "RMSE of persistence model for station 325: 29.146\n",
      "RMSE of persistence model for station 327: 69.511\n",
      "RMSE of persistence model for station 328: 22.198\n",
      "RMSE of persistence model for station 329: 20.599\n",
      "RMSE of persistence model for station 334: 48.629\n",
      "RMSE of persistence model for station 335: 54.160\n",
      "RMSE of persistence model for station 336: 35.466\n",
      "RMSE of persistence model for station 347: 61.195\n",
      "RMSE of persistence model for station 348: 38.969\n",
      "RMSE of persistence model for station 351: 27.341\n",
      "RMSE of persistence model for station 352: 38.061\n",
      "RMSE of persistence model for station 357: 40.776\n",
      "RMSE of persistence model for station 359: 171.241\n",
      "RMSE of persistence model for station 360: 27.394\n",
      "RMSE of persistence model for station 367: 76.992\n",
      "RMSE of persistence model for station 377: 41.204\n",
      "RMSE of persistence model for station 379: 92.226\n",
      "RMSE of persistence model for station 388: 67.524\n",
      "RMSE of persistence model for station 392: 21.821\n",
      "RMSE of persistence model for station 402: 127.985\n",
      "RMSE of persistence model for station 417: 59.824\n",
      "RMSE of persistence model for station 426: 77.933\n",
      "RMSE of persistence model for station 434: 62.024\n",
      "RMSE of persistence model for station 438: 32.511\n",
      "RMSE of persistence model for station 441: 33.274\n",
      "RMSE of persistence model for station 442: 78.572\n",
      "RMSE of persistence model for station 446: 62.652\n",
      "RMSE of persistence model for station 448: 37.335\n",
      "RMSE of persistence model for station 450: 59.408\n",
      "RMSE of persistence model for station 455: 42.901\n",
      "RMSE of persistence model for station 457: 51.909\n",
      "RMSE of persistence model for station 458: 51.708\n",
      "RMSE of persistence model for station 459: 63.849\n",
      "RMSE of persistence model for station 461: 51.974\n",
      "RMSE of persistence model for station 465: 25.906\n",
      "RMSE of persistence model for station 466: 61.294\n",
      "RMSE of persistence model for station 468: 74.596\n",
      "RMSE of persistence model for station 469: 53.406\n",
      "RMSE of persistence model for station 472: 85.755\n",
      "RMSE of persistence model for station 474: 60.099\n",
      "RMSE of persistence model for station 475: 52.158\n",
      "RMSE of persistence model for station 477: 117.123\n",
      "RMSE of persistence model for station 479: 44.951\n",
      "RMSE of persistence model for station 480: 28.467\n",
      "RMSE of persistence model for station 482: 43.985\n",
      "RMSE of persistence model for station 485: 48.233\n",
      "RMSE of persistence model for station 486: 72.846\n",
      "RMSE of persistence model for station 487: 37.558\n",
      "RMSE of persistence model for station 490: 100.563\n",
      "RMSE of persistence model for station 493: 47.365\n",
      "RMSE of persistence model for station 494: 52.473\n",
      "RMSE of persistence model for station 496: 62.839\n",
      "RMSE of persistence model for station 498: 79.053\n",
      "RMSE of persistence model for station 501: 31.235\n",
      "RMSE of persistence model for station 503: 55.108\n",
      "RMSE of persistence model for station 505: 71.008\n",
      "RMSE of persistence model for station 511: 68.636\n",
      "RMSE of persistence model for station 518: 70.780\n",
      "RMSE of persistence model for station 519: 255.743\n",
      "RMSE of persistence model for station 520: 136.981\n",
      "RMSE of persistence model for station 522: 41.507\n",
      "RMSE of persistence model for station 527: 59.528\n",
      "RMSE of persistence model for station 530: 40.210\n",
      "RMSE of persistence model for station 537: 57.594\n",
      "RMSE of persistence model for station 540: 58.726\n",
      "RMSE of persistence model for station 545: 21.002\n",
      "RMSE of persistence model for station 546: 57.694\n",
      "RMSE of persistence model for station 1978: 2345.430\n",
      "RMSE of persistence model for station 2012: 48.547\n",
      "RMSE of persistence model for station 2017: 35.306\n",
      "RMSE of persistence model for station 2021: 48.798\n",
      "RMSE of persistence model for station 3119: 25.547\n",
      "RMSE of persistence model for station 3141: 89.205\n",
      "RMSE of persistence model for station 3145: 21.715\n",
      "RMSE of persistence model for station 3156: 53.436\n",
      "RMSE of persistence model for station 3169: 19.508\n",
      "RMSE of persistence model for station 3223: 46.876\n",
      "RMSE of persistence model for station 3224: 48.225\n"
     ]
    }
   ],
   "source": [
    "persistence_dict = station_persistence(converged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the baseline prediction models for both the persistence and the (4,2,2) ARIMA model. We can take the difference and compare how well the station predicted with the RMSE model as opposed to a naive persistence model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{79: 3.7962704477675793,\n",
       " 127: 11.805605709833479,\n",
       " 137: 2.9182519408050887,\n",
       " 146: 4.0786193675213056,\n",
       " 147: 7.1219233287154324,\n",
       " 161: 7.6991461775646286,\n",
       " 164: 8.8672975193463657,\n",
       " 195: 10.302039848485897,\n",
       " 224: 2.9704447507717795,\n",
       " 229: 12.414697546158905,\n",
       " 232: 1.5721810599555042,\n",
       " 248: 3.1388375148802776,\n",
       " 251: 4.1601976494890351,\n",
       " 257: 5.2799492296955002,\n",
       " 260: 2.2969448522668934,\n",
       " 276: 2.2488861473088697,\n",
       " 280: 5.5408192376155654,\n",
       " 284: 8.0671135407347094,\n",
       " 304: 15.641364610264951,\n",
       " 311: 2.822956223831774,\n",
       " 312: 4.3776871486269222,\n",
       " 316: 4.4822174566553095,\n",
       " 319: 4.7451424007830667,\n",
       " 325: 3.7786334778126616,\n",
       " 327: 12.551683515546173,\n",
       " 328: -1.167532410006153,\n",
       " 329: -4.5028744298842156,\n",
       " 334: 8.309715941617803,\n",
       " 335: 10.528112581520872,\n",
       " 336: 5.371736948526415,\n",
       " 347: 10.282239218245714,\n",
       " 348: 5.1505805831779057,\n",
       " 351: 5.1808182704313595,\n",
       " 352: 0.43213605846706571,\n",
       " 357: 8.1479382053259073,\n",
       " 359: 47.451829836126407,\n",
       " 360: 4.7704181606435228,\n",
       " 367: 16.580221288194757,\n",
       " 377: 9.6836189649788658,\n",
       " 379: 24.645052299594866,\n",
       " 388: 12.311730356332603,\n",
       " 392: 1.6450122500836706,\n",
       " 402: 28.185708878857966,\n",
       " 417: 10.40463447242859,\n",
       " 426: 7.7815075104578284,\n",
       " 434: 11.870652648588454,\n",
       " 438: 3.6592466743797125,\n",
       " 441: 5.8104411185485567,\n",
       " 442: 15.211054050415584,\n",
       " 446: 8.8522598961529297,\n",
       " 448: 0.085804801572237466,\n",
       " 450: 9.7142431916928587,\n",
       " 455: 3.8887080193744907,\n",
       " 457: 8.0138170073728929,\n",
       " 458: 8.0918245794073016,\n",
       " 459: 2.5493520587282603,\n",
       " 461: 4.5103926141857684,\n",
       " 465: -1.2692646322510583,\n",
       " 466: 11.333072190525776,\n",
       " 468: 16.865378174761908,\n",
       " 469: 12.169526761857455,\n",
       " 472: 21.061281019087971,\n",
       " 474: 12.238685221649533,\n",
       " 475: 9.5665414277210061,\n",
       " 477: 29.459196059693966,\n",
       " 479: 6.2692888409652952,\n",
       " 480: 4.067009554185983,\n",
       " 482: 4.3408255149931207,\n",
       " 485: 9.3104394478371546,\n",
       " 486: 16.025465683747122,\n",
       " 487: 1.6693934159785115,\n",
       " 490: 24.9855419023732,\n",
       " 493: 8.5548673206553403,\n",
       " 494: 10.15825504853948,\n",
       " 496: 10.934933488891453,\n",
       " 498: 17.569103930532762,\n",
       " 501: 6.1490956558189716,\n",
       " 503: 9.2705721930253731,\n",
       " 505: 13.719854982373207,\n",
       " 511: 12.007688869222605,\n",
       " 518: 12.948694273336002,\n",
       " 519: 64.509689154818687,\n",
       " 520: 32.016912014894956,\n",
       " 522: 4.7995304554475311,\n",
       " 527: 12.128759242036011,\n",
       " 530: 6.6538963292556801,\n",
       " 537: 3.2965332488575498,\n",
       " 540: 9.3687550240011106,\n",
       " 545: -0.91196091694924775,\n",
       " 546: 12.14090873783298,\n",
       " 1978: 409.65716459573491,\n",
       " 2012: 11.777147551403658,\n",
       " 2017: 6.4754368616023612,\n",
       " 2021: 8.4609472960686318,\n",
       " 3119: 4.4646867336775493,\n",
       " 3141: 22.427884359521116,\n",
       " 3145: 3.2614072446964606,\n",
       " 3156: 13.211368405153181,\n",
       " 3169: 3.3344469981733198,\n",
       " 3223: 12.397470968563901,\n",
       " 3224: 6.7897323147949891}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_diff_dict = {x: persistence_dict[x] - station_id_RMSE[x] for x in station_id_RMSE}\n",
    "RMSE_diff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After differencing, we see that the vast majority of the stations predict better with an ARIMA model rather than with their corresponding persistence model. This is good to know, as applying a flavor of ARIMA model that is optimized for the system might be a viable solution for the individual substations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_diff_dict_df = pd.DataFrame([RMSE_diff_dict])\n",
    "RMSE_diff_dict_df = RMSE_diff_dict_df.T\n",
    "RMSE_diff_dict_df.columns = ['RMSE_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3.796270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>11.805606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.918252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>4.078619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>7.121923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RMSE_diff\n",
       "79    3.796270\n",
       "127  11.805606\n",
       "137   2.918252\n",
       "146   4.078619\n",
       "147   7.121923"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_diff_dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x185a1c2b0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFlCAYAAADGV7BOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17b8625c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_diff_dict_df[RMSE_diff_dict_df.RMSE_diff < 200].hist(bins=50, color='g')\n",
    "plt.xlabel('RMSE Difference')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Histogram of Differenced RMSE Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram of values for the RMSE, we can see that a vast majority are greater than zero. That said, there is a wide distribution of how this model performs with each individual staiton. \n",
    "\n",
    "# Applying (4,2,2) ARIMA to Individual Stations Conclusions\n",
    "I took the optimized ARIMA model for the system-wide stations to predict the number of rides, or demand, at each station within the Citi bike system. Of the originally selected 457 stations that had enough data points to train a model (250 non-NAN points), only 101 of the stations were able to converge upon a solution with the ARIMA model. Of the stations that were able to converge, 97 perfromed better than their baseline persistence model performance for prediction. \n",
    "\n",
    "### Pros and Cons of Using ARIMA for Forecasting\n",
    "Using ARIMA models for forecasting has shown to be a very hands-on forecasting approach that allows the user to understand the nuances of their model. Its rich in the amount of inputs that can be used, and allows for a great amount of feature engineering to be done as a side effect. However, ARIMA models are not very scalable to different, but similar, situations. In this case, I tried using an ARIMA model optimized for the system-wide traffic on the individual, constituent, stations, but many models could not converge upon a solution. This convergence issue is usually due to one of the AR, MA, or I variables not being compatible with the series itself.\n",
    "\n",
    "This convergence issue also makes sense. If you want to predict the movements of the S&P 500, there are many different parameters to take into account for the S&P 500 than there are for the stocks that make up that exchange.\n",
    "\n",
    "From this project, I can predict the demand for Citi Bikes on a system-wide scale and for various individual stations. As well, I have demonstrated the limitations that come with this model in modeling for the constituent pieces of the system. My recommendation to NYC or the Citi Bike program is to use this ARIMA model to predict traffic flows on certain days, and to think about how to implement changes that anticipate these increased rates of bicycle traffic within the city.\n",
    "\n",
    "### Future Work\n",
    "This project demonstrated the capability of an ARIMA model to predict system-wide traffic for the Citi Bike program. ARIMA models are great for understanding the seasonality of the data, engineering new features, and assessing how the model works in forecasting. In the future, I would use the newly-found features to create a neural network model that would be more robust and scalable to all of the stations in the city. The only issue would be the amount of time required to train all of the models. The combination of using ARIMA to assess system-wide information, use it to engineer new features, and an flexible neural network model could potentially create a prediction model that outperforms a plain and simple ARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
